# KNN (K-Nearest Neighbors) 분류기

Python으로 구현한 K-최근접 이웃 알고리즘 분류기입니다. 사용자로부터 학습 데이터와 새로운 데이터를 입력받아 분류하고, 시각화를 제공합니다.

## 주요 기능

- 유클리드 거리 기반 KNN 분류
- 터미널 기반 대화형 데이터 입력
- matplotlib을 통한 시각화 (2D)
- 다차원 데이터 지원 (시각화 시 2개 피쳐 선택 가능)

## 플로우 차트
![KNN 플로우 차](https://velog.velcdn.com/images/mourn5367/post/01140ea0-92e4-48fb-9089-76ef4fbebe56/image.jpg)

## 실행 방법

```bash
python new_Knn.py
```

## 프로그램 작업 순서 (코드 흐름)

### 1. 데이터 입력 단계

프로그램이 시작되면 터미널을 통해 순차적으로 데이터를 입력받습니다:

#### 1-1. K 값 입력
```
사용할 K값을 입력하세요: 3
```
- 분류에 사용할 이웃의 개수를 지정합니다
- 정수만 입력 가능

#### 1-2. 새로운 데이터 좌표 입력
```
분류할 새로운 데이터 좌표를 입력하세요 (예: 5,11): 6,10
```
- 분류하고자 하는 새로운 데이터 포인트를 입력합니다
- 형식: `x,y` 또는 `x,y,z,...` (쉼표로 구분)

#### 1-3. 학습 데이터 입력
```
학습 데이터를 입력하세요 (예: 4,12,C). 입력을 마치려면 '끝'을 입력하세요.
데이터 1: 2,10,A
데이터 2: 3,12,A
데이터 3: 8,8,B
데이터 4: 7,9,B
데이터 5: 끝
```
- 형식: `좌표1,좌표2,...,레이블` (마지막 값이 클래스 레이블)
- 최소 1개 이상의 학습 데이터 필요
- 입력 완료 시 `끝`, `done`, `exit` 중 하나를 입력

#### 1-4. 시각화 축 선택
```
데이터의 특징(피쳐)이 3개 있습니다.
시각화에 사용할 두 축의 번호를 입력하세요 (예: 1,2 / 생략하려면 Enter): 1,2
```
- 다차원 데이터일 경우, 시각화할 2개 축을 선택합니다
- 예: `1,2` → 첫 번째와 두 번째 피쳐를 x, y축으로 사용
- Enter 키만 누르면 시각화를 건너뜁니다

---

### 2. KNN 알고리즘 실행 단계

데이터 입력이 완료되면 `KnnClass.init_data()` 메서드가 호출되어 다음 순서로 처리됩니다:

#### 2-1. 거리 계산 (`cal_dist()`)
```python
def cal_dist(self):
```
- 새로운 데이터 포인트와 모든 학습 데이터 간의 유클리드 거리를 계산합니다
- 결과를 `(거리, 좌표, 레이블)` 형태로 `dist_info_list`에 저장합니다
- 거리 기준으로 오름차순 정렬합니다

**유클리드 거리 공식:**
```
distance = √[(x₁-x₂)² + (y₁-y₂)² + ...]
```

#### 2-2. 이웃 선택 및 분류 (`determine_knn()`)
```python
def determine_knn(self):
```
- 정렬된 리스트에서 상위 K개의 가장 가까운 이웃을 선택합니다
- 이웃들의 레이블을 추출합니다
- `Counter`를 사용한 다수결 투표로 최종 클래스를 결정합니다
- 예측 결과를 반환합니다

**출력 예시:**
```
새로운 데이터 [6, 10]의 예측 클래스는 'A' 입니다.
```

#### 2-3. 결과 시각화 (`visualize_knn()`)
```python
def visualize_knn(self):
```
시각화 축이 지정된 경우, 다음과 같이 그래프를 그립니다:

1. **클래스별 색상 지정**: 고유 레이블마다 다른 색상 할당
2. **학습 데이터 표시**: 모든 학습 데이터를 클래스별 색상으로 표시
3. **새로운 데이터 표시**: 검은색 별(★) 모양으로 크게 표시
4. **K개 이웃 강조**: 선택된 K개 이웃을 녹색 원으로 강조
5. **그래프 출력**: 제목, 축 레이블, 범례, 격자와 함께 출력

---

## 클래스 구조

### `KnnClass`

**주요 속성:**
- `sample_data`: 학습 데이터 좌표 리스트
- `labels`: 학습 데이터 레이블 리스트
- `k`: 이웃의 개수
- `new_point`: 분류할 새로운 데이터
- `show_columns`: 시각화할 축 번호 (튜플)
- `dist_info_list`: 거리 정보 저장 리스트

**주요 메서드:**
- `init_data()`: 데이터 초기화 및 전체 프로세스 실행
- `cal_dist()`: 거리 계산 및 정렬
- `determine_knn()`: KNN 분류 수행
- `visualize_knn()`: 결과 시각화
- `euclidean_distance()`: 유클리드 거리 계산

---

## 헬퍼 함수

### `get_data_from_terminal()`
터미널에서 K값, 새로운 데이터, 학습 데이터를 입력받습니다.

### `get_visualization_columns()`
시각화할 피쳐 축을 선택받습니다.

---

## 실행 예시

```
사용할 K값을 입력하세요: 3

분류할 새로운 데이터 좌표를 입력하세요 (예: 5,11): 6,10

학습 데이터를 입력하세요 (예: 4,12,C). 입력을 마치려면 '끝'을 입력하세요.
데이터 1: 2,10,A
데이터 2: 3,12,A
데이터 3: 4,11,A
데이터 4: 8,8,B
데이터 5: 7,9,B
데이터 6: 9,7,B
데이터 7: 끝

데이터의 특징(피쳐)이 2개 있습니다.
시각화에 사용할 두 축의 번호를 입력하세요 (예: 1,2 / 생략하려면 Enter): 1,2

새로운 데이터 [6.0, 10.0]의 예측 클래스는 'A' 입니다.
[시각화 그래프 출력]
```

---

## 의존성

```bash
pip install matplotlib
```

기본 라이브러리:
- `math`: 유클리드 거리 계산
- `collections.Counter`: 다수결 투표

---

## 주의사항

- 학습 데이터의 모든 좌표는 동일한 차원을 가져야 합니다
- K값은 학습 데이터 개수보다 작거나 같아야 합니다
- 시각화는 2차원만 지원하므로, 다차원 데이터는 2개 피쳐만 선택해야 합니다
- 레이블은 문자열 또는 숫자 모두 가능합니다

---

## 코드 실행 흐름 요약

```
[시작]
   ↓
[get_data_from_terminal()] → K값, 새 데이터, 학습 데이터 입력
   ↓
[get_visualization_columns()] → 시각화 축 선택
   ↓
[KnnClass 인스턴스 생성]
   ↓
[init_data()] 호출
   ├─ [cal_dist()] → 거리 계산 및 정렬
   ├─ [determine_knn()] → K개 이웃 선택 → 다수결 투표
   ├─ 예측 결과 출력
   └─ [visualize_knn()] → 그래프 시각화
   ↓
[종료]
```

